transformer
[array(['T1003.001', 'T1005', 'T1012', 'T1016', 'T1021.001', 'T1027',
       'T1033', 'T1036.005', 'T1041', 'T1047', 'T1053.005', 'T1055',
       'T1056.001', 'T1057', 'T1059.003', 'T1068', 'T1070.004',
       'T1071.001', 'T1072', 'T1074.001', 'T1078', 'T1082', 'T1083',
       'T1090', 'T1095', 'T1105', 'T1106', 'T1110', 'T1112', 'T1113',
       'T1140', 'T1190', 'T1204.002', 'T1210', 'T1218.011', 'T1219',
       'T1484.001', 'T1518.001', 'T1543.003', 'T1547.001', 'T1548.002',
       'T1552.001', 'T1557.001', 'T1562.001', 'T1564.001', 'T1566.001',
       'T1569.002', 'T1570', 'T1573.001', 'T1574.002'], dtype=object)]
                                                text      label
0  This file extracts credentials from LSASS simi...  T1003.001
1  It calls OpenProcess on lsass.exe with access ...  T1003.001
2  It spreads to Microsoft Windows machines using...      T1210
3                   SMB exploitation via EternalBlue      T1210
4                 SMBv1 Exploitation via EternalBlue      T1210
5  has the capability to exploit SMBv1 via the we...      T1210
6                      SMB copy and remote execution      T1570
7  This thread is then used to execute the SMB co...      T1570
8                      SMB copy and remote execution      T1570
9                      SMB Copy and Remote Execution      T1570
GPT2ForSequenceClassification(
  (transformer): GPT2Model(
    (wte): Embedding(50265, 768)
    (wpe): Embedding(514, 768)
    (drop): Dropout(p=0.1, inplace=False)
    (h): ModuleList(
      (0-11): 12 x GPT2Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): GPT2Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): GPT2MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (act): NewGELUActivation()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (score): Linear(in_features=768, out_features=50, bias=False)
)
tensor([[  273, 12233,  3696,  ..., 50256, 50256, 50256],
        [11085,  8794,   284,  ..., 50256, 50256, 50256],
        [ 1169, 17392,  2438,  ..., 50256, 50256, 50256],
        ...,
        [17953,  7530,  8861,  ..., 50256, 50256, 50256],
        [ 1169, 15458,  2393,  ..., 50256, 50256, 50256],
        [   83,  1124, 23322,  ..., 50256, 50256, 50256]])
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]])
tensor(4071.)
                  P         R        F1      #
T1003.001  0.925926  1.000000  0.961538   25.0
T1005      0.700000  0.538462  0.608696   13.0
T1012      0.000000  0.000000  0.000000    5.0
T1016      1.000000  0.705882  0.827586   17.0
T1021.001  0.769231  1.000000  0.869565   20.0
T1027      0.923077  0.875912  0.898876  137.0
T1033      1.000000  0.222222  0.363636    9.0
T1036.005  0.866667  0.650000  0.742857   20.0
T1041      0.833333  0.416667  0.555556   12.0
T1047      0.785714  0.916667  0.846154   12.0
T1053.005  1.000000  0.952381  0.975610   21.0
T1055      0.923077  0.979592  0.950495   49.0
T1056.001  1.000000  1.000000  1.000000   11.0
T1057      0.941176  0.941176  0.941176   17.0
T1059.003  0.805195  0.984127  0.885714   63.0
T1070.004  0.888889  0.666667  0.761905   12.0
T1071.001  0.805556  0.966667  0.878788   30.0
T1072      0.000000  0.000000  0.000000    1.0
T1074.001  0.000000  0.000000  0.000000    4.0
T1078      0.833333  0.921053  0.875000   38.0
T1082      0.750000  0.827586  0.786885   29.0
T1083      0.636364  0.736842  0.682927   19.0
T1090      0.875000  0.840000  0.857143   25.0
T1095      1.000000  0.571429  0.727273    7.0
T1105      0.612500  0.924528  0.736842   53.0
T1106      0.921053  0.945946  0.933333   37.0
T1110      0.800000  0.800000  0.800000   10.0
T1112      0.812500  0.962963  0.881356   27.0
T1113      1.000000  0.600000  0.750000   10.0
T1140      0.890909  0.960784  0.924528  102.0
T1190      0.833333  0.714286  0.769231    7.0
T1204.002  0.764706  0.565217  0.650000   23.0
T1210      0.000000  0.000000  0.000000    1.0
T1218.011  1.000000  1.000000  1.000000    7.0
T1219      1.000000  0.454545  0.625000   11.0
T1484.001  0.000000  0.000000  0.000000    3.0
T1518.001  1.000000  0.666667  0.800000    6.0
T1543.003  0.928571  0.812500  0.866667   16.0
T1547.001  0.500000  0.733333  0.594595   15.0
T1548.002  1.000000  0.875000  0.933333    8.0
T1552.001  0.000000  0.000000  0.000000    1.0
T1557.001  0.000000  0.000000  0.000000    1.0
T1562.001  0.888889  1.000000  0.941176   16.0
T1564.001  0.000000  0.000000  0.000000    4.0
T1566.001  0.947368  1.000000  0.972973   18.0
T1569.002  0.000000  0.000000  0.000000    7.0
T1570      0.500000  0.636364  0.560000   11.0
T1573.001  1.000000  0.307692  0.470588   13.0
T1574.002  0.823529  0.933333  0.875000   15.0
(micro)    0.837917  0.837917  0.837917    NaN
(macro)    0.703794  0.645030  0.654735    NaN
