transformer
[array(['T1003.001', 'T1005', 'T1012', 'T1016', 'T1021.001', 'T1027',
       'T1033', 'T1036.005', 'T1041', 'T1047', 'T1053.005', 'T1055',
       'T1056.001', 'T1057', 'T1059.003', 'T1068', 'T1070.004',
       'T1071.001', 'T1072', 'T1074.001', 'T1078', 'T1082', 'T1083',
       'T1090', 'T1095', 'T1105', 'T1106', 'T1110', 'T1112', 'T1113',
       'T1140', 'T1190', 'T1204.002', 'T1210', 'T1218.011', 'T1219',
       'T1484.001', 'T1518.001', 'T1543.003', 'T1547.001', 'T1548.002',
       'T1552.001', 'T1557.001', 'T1562.001', 'T1564.001', 'T1566.001',
       'T1569.002', 'T1570', 'T1573.001', 'T1574.002'], dtype=object)]
                                                text      label
0  This file extracts credentials from LSASS simi...  T1003.001
1  It calls OpenProcess on lsass.exe with access ...  T1003.001
2  It spreads to Microsoft Windows machines using...      T1210
3                   SMB exploitation via EternalBlue      T1210
4                 SMBv1 Exploitation via EternalBlue      T1210
5  has the capability to exploit SMBv1 via the we...      T1210
6                      SMB copy and remote execution      T1570
7  This thread is then used to execute the SMB co...      T1570
8                      SMB copy and remote execution      T1570
9                      SMB Copy and Remote Execution      T1570
BertForSequenceClassification(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31090, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=50, bias=True)
)
tensor([[  102,  3017,  2737,  ...,     0,     0,     0],
        [  102, 13661,   137,  ...,     0,     0,     0],
        [  102,  3740,  7551,  ...,     0,     0,     0],
        ...,
        [  102, 16454,   147,  ...,     0,     0,     0],
        [  102, 11564,   453,  ...,     0,     0,     0],
        [  102,  1834, 30118,  ...,     0,     0,     0]])
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]])
tensor(4071.)
                  P         R        F1      #
T1003.001  0.666667  0.571429  0.615385   14.0
T1005      0.555556  0.714286  0.625000    7.0
T1012      1.000000  0.333333  0.500000    3.0
T1016      0.416667  0.909091  0.571429   11.0
T1021.001  0.800000  0.923077  0.857143   13.0
T1027      0.788079  0.804054  0.795987  148.0
T1033      0.833333  0.909091  0.869565   11.0
T1036.005  0.454545  0.769231  0.571429   13.0
T1041      1.000000  0.350000  0.518519   20.0
T1047      0.789474  0.937500  0.857143   16.0
T1053.005  0.862069  1.000000  0.925926   25.0
T1055      0.869565  0.769231  0.816327   52.0
T1056.001  0.944444  1.000000  0.971429   17.0
T1057      0.750000  1.000000  0.857143   15.0
T1059.003  0.960784  0.720588  0.823529   68.0
T1068      0.400000  1.000000  0.571429    2.0
T1070.004  0.636364  0.636364  0.636364   22.0
T1071.001  0.903226  0.903226  0.903226   31.0
T1074.001  0.333333  1.000000  0.500000    3.0
T1078      0.878788  0.690476  0.773333   42.0
T1082      0.837838  0.911765  0.873239   34.0
T1083      0.736842  0.777778  0.756757   18.0
T1090      0.658537  0.843750  0.739726   32.0
T1095      0.733333  0.846154  0.785714   13.0
T1105      0.672727  0.822222  0.740000   45.0
T1106      0.884615  0.676471  0.766667   34.0
T1110      0.736842  0.933333  0.823529   15.0
T1112      0.809524  0.944444  0.871795   18.0
T1113      1.000000  0.888889  0.941176    9.0
T1140      0.849462  0.897727  0.872928   88.0
T1190      0.800000  0.400000  0.533333   10.0
T1204.002  0.933333  0.777778  0.848485   18.0
T1210      0.000000  0.000000  0.000000    1.0
T1218.011  0.909091  1.000000  0.952381   10.0
T1219      0.250000  0.222222  0.235294    9.0
T1484.001  0.000000  0.000000  0.000000    5.0
T1518.001  0.500000  1.000000  0.666667    6.0
T1543.003  0.578947  1.000000  0.733333   11.0
T1547.001  0.777778  0.777778  0.777778    9.0
T1548.002  0.800000  1.000000  0.888889    8.0
T1552.001  0.666667  0.285714  0.400000    7.0
T1562.001  0.937500  0.833333  0.882353   18.0
T1564.001  1.000000  0.800000  0.888889    5.0
T1566.001  0.888889  0.842105  0.864865   19.0
T1569.002  0.500000  0.166667  0.250000    6.0
T1570      1.000000  0.142857  0.250000   14.0
T1573.001  0.500000  0.100000  0.166667   10.0
T1574.002  1.000000  0.846154  0.916667   13.0
(micro)    0.779961  0.779961  0.779961    NaN
(macro)    0.725100  0.722461  0.687238    NaN
