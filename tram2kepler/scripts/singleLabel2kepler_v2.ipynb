{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:09.556520Z",
     "start_time": "2024-04-12T08:27:09.502166Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get tram single label data:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb1bf61ccb51e514"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: illegal option -- .\r\n",
      "usage: mkdir [-pv] [-m mode] directory_name ...\r\n",
      "--2024-04-12 10:27:09--  https://raw.githubusercontent.com/center-for-threat-informed-defense/tram/main/data/tram2-data/single_label.json\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8002::154, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1024483 (1000K) [text/plain]\r\n",
      "Saving to: ‘../data/input/single_label.json’\r\n",
      "\r\n",
      "../data/input/singl 100%[===================>]   1000K  --.-KB/s    in 0.1s    \r\n",
      "\r\n",
      "2024-04-12 10:27:10 (9.42 MB/s) - ‘../data/input/single_label.json’ saved [1024483/1024483]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p../data/input\n",
    "!wget -O../data/input/single_label.json https://raw.githubusercontent.com/center-for-threat-informed-defense/tram/main/data/tram2-data/single_label.json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:10.381822Z",
     "start_time": "2024-04-12T08:27:09.510254Z"
    }
   },
   "id": "9fafa36e6fc8fdee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this version, we will consider the text, tactic and document title, all 3 of them as nodes.\n",
    "The ontology then will be:\n",
    "\n",
    "Nodes: \n",
    "    text, technique, doc_title\n",
    "    \n",
    "Relationships: \n",
    "    uses, found-in\n",
    "\n",
    "Graph triple types will be:\n",
    "    text uses technique\n",
    "    text found-in doc_title\n",
    "    technique found-in doc_title"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "599d97678482b091"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data = pd.read_json('../data/input/single_label.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:10.394020Z",
     "start_time": "2024-04-12T08:27:10.382975Z"
    }
   },
   "id": "7f78d849a99e5804"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text      label  \\\n0     This file extracts credentials from LSASS simi...  T1003.001   \n1     It calls OpenProcess on lsass.exe with access ...  T1003.001   \n2     It spreads to Microsoft Windows machines using...      T1210   \n3                      SMB exploitation via EternalBlue      T1210   \n4                    SMBv1 Exploitation via EternalBlue      T1210   \n...                                                 ...        ...   \n5084  collects local files and information from the ...      T1005   \n5085      uses HTTPS to communicate with its C2 servers  T1071.001   \n5086  samples have used HTTP over ports 447 and 8082...  T1071.001   \n5087  downloads several additional files and saves t...      T1105   \n5088  uses a custom crypter leveraging Microsoft’s C...  T1573.001   \n\n                                              doc_title  \n0     NotPetya Technical Analysis  A Triple Threat F...  \n1     NotPetya Technical Analysis  A Triple Threat F...  \n2     NotPetya Technical Analysis  A Triple Threat F...  \n3     NotPetya Technical Analysis  A Triple Threat F...  \n4     NotPetya Technical Analysis  A Triple Threat F...  \n...                                                 ...  \n5084                          AA21076A TrickBot Malware  \n5085                          AA21076A TrickBot Malware  \n5086                          AA21076A TrickBot Malware  \n5087                          AA21076A TrickBot Malware  \n5088                          AA21076A TrickBot Malware  \n\n[5089 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>doc_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This file extracts credentials from LSASS simi...</td>\n      <td>T1003.001</td>\n      <td>NotPetya Technical Analysis  A Triple Threat F...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It calls OpenProcess on lsass.exe with access ...</td>\n      <td>T1003.001</td>\n      <td>NotPetya Technical Analysis  A Triple Threat F...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>It spreads to Microsoft Windows machines using...</td>\n      <td>T1210</td>\n      <td>NotPetya Technical Analysis  A Triple Threat F...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SMB exploitation via EternalBlue</td>\n      <td>T1210</td>\n      <td>NotPetya Technical Analysis  A Triple Threat F...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SMBv1 Exploitation via EternalBlue</td>\n      <td>T1210</td>\n      <td>NotPetya Technical Analysis  A Triple Threat F...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5084</th>\n      <td>collects local files and information from the ...</td>\n      <td>T1005</td>\n      <td>AA21076A TrickBot Malware</td>\n    </tr>\n    <tr>\n      <th>5085</th>\n      <td>uses HTTPS to communicate with its C2 servers</td>\n      <td>T1071.001</td>\n      <td>AA21076A TrickBot Malware</td>\n    </tr>\n    <tr>\n      <th>5086</th>\n      <td>samples have used HTTP over ports 447 and 8082...</td>\n      <td>T1071.001</td>\n      <td>AA21076A TrickBot Malware</td>\n    </tr>\n    <tr>\n      <th>5087</th>\n      <td>downloads several additional files and saves t...</td>\n      <td>T1105</td>\n      <td>AA21076A TrickBot Malware</td>\n    </tr>\n    <tr>\n      <th>5088</th>\n      <td>uses a custom crypter leveraging Microsoft’s C...</td>\n      <td>T1573.001</td>\n      <td>AA21076A TrickBot Malware</td>\n    </tr>\n  </tbody>\n</table>\n<p>5089 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:10.414600Z",
     "start_time": "2024-04-12T08:27:10.395838Z"
    }
   },
   "id": "f9065632917dda87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting all unique labels, doc_titles and text:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5a11df2ebf91f89"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['T1003.001', 'T1210', 'T1570', 'T1140', 'T1218.011', 'T1059.003',\n       'T1057', 'T1518.001', 'T1106', 'T1082', 'T1016', 'T1078', 'T1047',\n       'T1027', 'T1056.001', 'T1083', 'T1053.005', 'T1070.004', 'T1105',\n       'T1090', 'T1005', 'T1574.002', 'T1071.001', 'T1484.001',\n       'T1204.002', 'T1055', 'T1562.001', 'T1033', 'T1566.001', 'T1219',\n       'T1547.001', 'T1021.001', 'T1543.003', 'T1569.002', 'T1036.005',\n       'T1112', 'T1041', 'T1110', 'T1190', 'T1564.001', 'T1113',\n       'T1573.001', 'T1095', 'T1552.001', 'T1012', 'T1074.001',\n       'T1548.002', 'T1068', 'T1072', 'T1557.001'], dtype=object)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_techniques = data['label'].explode().dropna().unique()\n",
    "all_techniques"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:10.415436Z",
     "start_time": "2024-04-12T08:27:10.406570Z"
    }
   },
   "id": "30af359f89d46de8"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['NotPetya Technical Analysis  A Triple Threat File Encryption MFT Encryption Credential Theft',\n       'Earth Zhulong Familiar Patterns Target Southeast Asian Firms',\n       'Malware Spotlight Camaro Dragons TinyNote Backdoor',\n       'Rorschach  A New Sophisticated and Fast Ransomware  Check Point Research',\n       'Bypassing Intel CET with Counterfeit Objects  OffSec',\n       'Emotet Strikes Again  LNK File Leads to Domain Wide Ransomware  The DFIR Report',\n       'Malware Analysis LummaC2 Stealer',\n       'FedEx Phishing Campaign Abusing TrustedForm and PAAY',\n       'Take a NetWalk on the Wild Side',\n       'Malicious OAuth applications used to compromise email servers and spread spam  Microsoft Security Blog',\n       'Nefilim Ransomware',\n       'Deja Vu All Over Again Tax Scammers at Large',\n       'Threat Assessment Black Basta Ransomware',\n       'Hafniuminspired cyberattacks neutralized by AI',\n       'eSentire Threat Intelligence Malware Analysis BatLoader',\n       'Early Bird Catches the Wormhole Observations from the StellarParticle Campaign',\n       '3CXDesktopApp Backdoored in a Suspected Lazarus Campaign\\xa0\\xa0',\n       'Not just an infostealer Gopuram backdoor deployed through 3CX supply chain attack',\n       'AA21200A Tactics Techniques and Procedures of Indicted APT40 Actors Associated with Chinas MSS Hainan State Security Department',\n       'Operation Spalax Targeted malware attacks in Colombia',\n       'LAPSUS Recent techniques tactics and procedures',\n       'Detecting Credential Stealing Attacks Through Active InNetwork Defense',\n       'Understanding DNS attacks Identifying and patching vulnerabilities  Snyk',\n       'EvilExtractor  AllinOne Stealer',\n       'LockBit 20 How This RaaS Operates and How to Protect Against It',\n       'SOC Team Essentials  How to Investigate and Track the 8220 Gang Cloud Threat',\n       'Fantasy  a new Agrius wiper deployed through a supplychain attack',\n       'AA22320A Iranian GovernmentSponsored APT Actors Compromise Federal Network Deploy Crypto Miner Credential Harvester',\n       'New Horabot campaign targets the Americas',\n       'Vice Society leverages PrintNightmare in ransomware attacks',\n       'UNC215 Spotlight on a Chinese Espionage Campaign in Israel',\n       'Dark Web Profile MuddyWater APT Group',\n       'Cobalt Strike a Defenders Guide  Part 2',\n       'Tailoring Sandbox Techniques to Hidden Threats',\n       'Babadeda Crypter targeting crypto NFT and DeFi communities',\n       'Threat Assessment BlackCat Ransomware',\n       'AA21200B Chinese StateSponsored Cyber Operations Observed TTPs',\n       'Vulnerability in Essential Addons for Elementor Leads to Mass Infection',\n       'StopRansomware Royal Ransomware',\n       'GuLoader VBScript Variant Returns with PowerShell Updates',\n       'Xollam the Latest Face of TargetCompany',\n       'Operation Tainted Love  Chinese APTs Target Telcos in New Attacks',\n       'Defending Users NAS Devices From Evolving Threats',\n       'Enigma Stealer Targets Cryptocurrency Industry with Fake Jobs',\n       'ExConti and FIN7 Actors Collaborate with New Domino Backdoor',\n       'Fat Cats',\n       'Analysis on recent wiper attacks examples and how wiper malware works',\n       'Higaisa or Winnti APT41 backdoors old and new',\n       'Operation Harvest A Deep Dive into a Longterm Campaign',\n       'Prilex Brazilian PoS malware evolution',\n       'The Rising Trend of OneNote Documents for Malware delivery',\n       'ZeroDay Vulnerability in MOVEit Transfer Exploited for Data Theft',\n       'Iranian GovernmentSponsored APT Actors Compromise Federal Network Deploy Crypto Miner Credential Harvester',\n       'FinSpy unseen findings',\n       'Vice Society Profiling a Persistent Threat to the Education Sector',\n       'Spike in LokiBot Activity During Final Week of 2022',\n       'Nationstate threat actor Mint Sandstorm refines tradecraft to attack highvalue targets',\n       'GuLoader Demystified Unraveling its Vectored Exception Handler Approach',\n       'Pack it Secretly Earth Pretas Updated Stealthy Strategies',\n       'Malware Reverse Engineering for Beginners  Part 2',\n       'Supply Chain Risk from Gigabyte App Center Backdoor  Eclypsium  Supply Chain Security for the Modern Enterprise',\n       'Gotta Catch Em All  Understanding the NetSupport RAT Campaigns Hiding Behind Pokemon Lures',\n       'Uncommon infection methodspart 2',\n       'German users targeted with Gootkit banker or REvil ransomware',\n       'New IcedID variants shift from bank fraud to malware delivery',\n       'BumbleBee Roasts Its Way to Domain Admin',\n       'Operation CMDStealer Financially Motivated Campaign Leverages CMDBased Scripts and LOLBaS for Online Banking Theft in Portugal Peru and Mexico',\n       'AA20336A Advanced Persistent Threat Actors Targeting US Think Tanks',\n       'Do Not Cross The RedLine Stealer Detections and Analysis',\n       'Conti Team One Splinter Group Resurfaces as Royal Ransomware with Callback Phishing Attacks',\n       'Threat Advisory 3CX Softphone Supply Chain Compromise',\n       'Malware Disguised as Document from Ukraines Energoatom Delivers Havoc Demon Backdoor',\n       'In the footsteps of the Fancy Bear PowerPoint\\xa0mouseover event abused to deliver Graphite implants',\n       'Can You See It Now An Emerging LockBit Campaign',\n       'WTB Remote Mac Exploitation Via Custom URL Schemes',\n       'Dead or Alive An Emotet Story', 'Conti Ransomware',\n       'Microsoft research uncovers new Zerobot capabilities  Microsoft Security Blog',\n       'Just Because Its Old Doesnt Mean You Throw It Away Including Malware',\n       'Carbon Blacks TrueBot Detection',\n       'ITG10 Likely Targeting South Korean Entities of Interest to the Democratic Peoples Republic of Korea DPRK',\n       'Abusing cloud services to fly under the radar',\n       'Transparent Tribe APT36  PakistanAligned Threat Actor Expands Interest in Indian Education Sector',\n       'SYS01 Stealer Will Steal Your Facebook Info',\n       'Banking Trojan Techniques How Financially Motivated Malware Became Infrastructure',\n       'Tracking Traces of Malware Disguised as Hancom Office Document File and Being Distributed RedEyes',\n       'Attackers use domain fronting technique to target Myanmar with Cobalt Strike',\n       'Akira Ransomware is bringin 1988 back',\n       'WTB Adwind Trojan Circumvents Antivirus Software To Infect Your PC',\n       'Hungry for data ModPipe backdoor hits POS software used in hospitality sector',\n       'Update 2 3CX users under DLLsideloading attack What you need to know',\n       'GoBruteforcer GolangBased Botnet Actively Harvests Web Servers',\n       'The LockBit ransomware kinda comes for macOS',\n       'IronNetInjector Turlas New Malware Loading Tool',\n       'Dissecting One of APT29s Fileless WMI and PowerShell Backdoors POSHSPY',\n       'Hancitor Infection Chain Analysis An Examination of its Unpacking Routine and Execution Techniques',\n       'Smoking Out a DARKSIDE Affiliates Supply Chain Software Compromise',\n       'AA20258A Chinese Ministry of State SecurityAffiliated Cyber Threat Actor Activity',\n       'Phishing Campaign Targets Chinese Nuclear Energy Industry',\n       'Latin American Governments Targeted By Ransomware',\n       'Chinese Threat Actor Used Modified Cobalt Strike Variant to Attack Taiwanese Critical Infrastructure',\n       'OpenSource Gh0st RAT Still Haunting Inboxes 15 Years After Release',\n       'CrowdStrike Uncovers I2Pminer MacOS Mineware Variant',\n       'Evasive NoEscape Ransomware Uses Reflective DLL Injection',\n       'Stolen certificates in two waves of ransomware and wiper attacks',\n       'BlueNoroff introduces new methods bypassing MoTW',\n       'Fork in the Ice The New Era of IcedID',\n       'Kimsuky Strikes Again  New Social Engineering Campaign Aims to Steal Credentials and Gather Strategic Intelligence',\n       'Warning New attack campaign utilized a new 0day RCE vulnerability on Microsoft Exchange Server',\n       'Recent TZW Campaigns Revealed As Part of GlobeImposter Malware Family',\n       'MERCURY and DEV1084 Destructive attack on hybrid environment',\n       'ZipJar a little bit unexpected attack chain',\n       'Whos swimming in South Korean waters Meet ScarCrufts Dolphin',\n       'Iron Tigers SysUpdate Reappears Adds Linux Targeting',\n       'Unwrapping Ursnifs Gifts  The DFIR Report',\n       'Qakbot Returns to ISO Delivery For Now',\n       'BeeWare of Trigona An Emerging Ransomware Strain',\n       'SharpPanda APT Campaign Expands its Arsenal Targeting G20 Nations',\n       'Increasing The Sting of HIVE Ransomware',\n       'ViperSoftX Updates Encryption Steals Data',\n       'CISA Red Team Shares Key Findings to Improve Monitoring and Hardening of Networks',\n       'McAfee Defenders Blog NetWalker',\n       'Technical Analysis Black Basta Malware Overview',\n       'Earth Pretas Cyberespionage Campaign Hits Over 200',\n       'Updated New Evidence Emerges to Suggest WatchDog Was Behind Crypto Campaign',\n       'These arent the apps youre looking for fake installers targeting Southeast and East Asia',\n       'Tax firms targeted by precision malware attacks',\n       'BazarLoader Mocks Researchers in December 2020 Malspam Campaign',\n       'Investigation with a twist an accidental APT attack and averted data destruction',\n       'Threat actors strive to cause Tax Day headaches',\n       'Revisiting the NSISbased crypter',\n       '\\xa0LockBit Ransomware 20 Resurfaces',\n       'Too Log Didnt Read  Unknown Actor Using CLFS Log Files for Stealth',\n       'Ransom Cartel Ransomware A Possible Connection With REvil',\n       'Malicious ISO File Leads to Domain Wide Ransomware  The DFIR Report',\n       'SeroXen RAT for sale',\n       'A lookback under the TA410 umbrella Its cyberespionage TTPs and activity',\n       'When byte code bites Who checks the contents of compiled Python files',\n       'MoonBounce the dark side of UEFI firmware',\n       'Threat Actors Use MSBuild to Deliver RATs Filelessly',\n       'How to Detect Cobalt Strike',\n       'New RapperBot Campaign  We Know What You Bruting for this Time',\n       'Inside the Mind of a Cyber Attacker from Malware creation to Data Exfiltration Part 1',\n       'CatB Ransomware  File Locker Sharpens Its Claws to Steal Data with MSDTC Service DLL Hijacking',\n       'Analyzing Solorigate the compromised DLL file that started a sophisticated cyberattack and how Microsoft Defender helps protect customers',\n       'Horabot campaign targeted businesses for more than two years before finally being discovered',\n       'StopRansomware Hive Ransomware',\n       'Linux malware strengthens links between Lazarus and the 3CX supplychain attack',\n       'AA21076A TrickBot Malware'], dtype=object)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_titles = data['doc_title'].explode().dropna().unique()\n",
    "doc_titles"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:10.415854Z",
     "start_time": "2024-04-12T08:27:10.409921Z"
    }
   },
   "id": "37005b13e7409616"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['This file extracts credentials from LSASS similar to Mimikatz.',\n       'It calls OpenProcess on lsass.exe with access flag set to VM_READ, and looks for the modules wdigest.dll and lsasrv.dll loaded in the lsass.exe process.',\n       'It spreads to Microsoft Windows machines using several propagation methods, including the EternalBlue exploit for the CVE-2017-0144 vulnerability in the SMB service.',\n       ..., 'samples have used HTTP over ports 447 and 8082 for C2.',\n       \"downloads several additional files and saves them to the victim's machine.\",\n       'uses a custom crypter leveraging Microsoft’s CryptoAPI to encrypt C2 traffic.'],\n      dtype=object)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data['text'].to_numpy()\n",
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:10.417651Z",
     "start_time": "2024-04-12T08:27:10.414822Z"
    }
   },
   "id": "7afaf4f6e9d6f3cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adding them all in one place labels, text, doc_titles:\n",
    "there are 50 labels, 149 doc_titles and 5089 text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae7539994504a132"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['T1003.001', 'T1210', 'T1570', ...,\n       'samples have used HTTP over ports 447 and 8082 for C2.',\n       \"downloads several additional files and saves them to the victim's machine.\",\n       'uses a custom crypter leveraging Microsoft’s CryptoAPI to encrypt C2 traffic.'],\n      dtype=object)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = np.concatenate((all_techniques, doc_titles, text))\n",
    "nodes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:10.423295Z",
     "start_time": "2024-04-12T08:27:10.416741Z"
    }
   },
   "id": "8feb6375c394f709"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The node list will then have \n",
    "    0-49 techniques\n",
    "    50-198 doc_titles \n",
    "    199-5287 text\n",
    "    \n",
    "Now to make the numeric triples, we will use the indexes of the nodes from the nodes list.\n",
    "\n",
    "\n",
    "Let us say that of the two relationships, uses = 0 and found-in = 1\n",
    "\n",
    "1. we make the triples for text uses technique\n",
    "2. we make the triples for text found-in doc_title\n",
    "3. we make the triples for technique found-in doc_title"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73c3a4f932718d8d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "triples = []\n",
    "tech2doc = []\n",
    "\n",
    "np_data = data.to_numpy()\n",
    "\n",
    "for row in np_data:\n",
    "    text_index = np.where(nodes == row[0])[0][0]\n",
    "    technique_index = np.where(nodes == row[1])[0][0]\n",
    "    doc_title_index = np.where(nodes == row[2])[0][0]\n",
    "\n",
    "    triples.append((text_index, 0, technique_index))\n",
    "    triples.append((text_index, 1, doc_title_index))\n",
    "    tech2doc.append((technique_index, 1, doc_title_index))\n",
    "\n",
    "tech2doc = np.unique(tech2doc, axis=0)\n",
    "triples = np.array(triples)\n",
    "triples = np.append(triples, tech2doc, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:10.953538Z",
     "start_time": "2024-04-12T08:27:10.420226Z"
    }
   },
   "id": "285010d75de580e7"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[199,   0,   0],\n       [199,   1,  50],\n       [200,   0,   0],\n       ...,\n       [ 48,   1, 170],\n       [ 48,   1, 183],\n       [ 49,   1, 170]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:10.953995Z",
     "start_time": "2024-04-12T08:27:10.947811Z"
    }
   },
   "id": "81537cb5a95cf7de"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "11868"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:10.955581Z",
     "start_time": "2024-04-12T08:27:10.953665Z"
    }
   },
   "id": "8a764d37b4b88e34"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "assert len(triples) == 2 * len(np_data) + len(tech2doc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:10.961647Z",
     "start_time": "2024-04-12T08:27:10.955707Z"
    }
   },
   "id": "c73d7e1731c3ec27"
  },
  {
   "cell_type": "markdown",
   "source": [
    "split the triples into validation, test and save them to a file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5cdbedc0434fb2c"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: illegal option -- .\r\n",
      "usage: mkdir [-pv] [-m mode] directory_name ...\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p../data/output/single"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:11.075830Z",
     "start_time": "2024-04-12T08:27:10.957979Z"
    }
   },
   "id": "ffaa092cfdc6cb7a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "output = \"../data/output/single\"\n",
    "pd.DataFrame(triples).to_csv(output + '/triples.txt', index=False, header=False, sep=' ')\n",
    "train, valid = train_test_split(triples, test_size=0.05)\n",
    "pd.DataFrame(train).to_csv(output + '/train.txt', index=False, header=False, sep=' ')\n",
    "pd.DataFrame(valid).to_csv(output + '/valid.txt', index=False, header=False, sep=' ')\n",
    "assert len(train) + len(valid) == len(triples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:11.103639Z",
     "start_time": "2024-04-12T08:27:11.075765Z"
    }
   },
   "id": "17aea83473e80888"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also train test validation split the nodes.txt for MLM "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20e884a9dc0d5054"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def write_file(file_path, _list):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for _row in _list:\n",
    "            f.write(_row.replace(\"\\n\", r\"\\n\").replace(\"\\t\", r\"\\t\") + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:11.107740Z",
     "start_time": "2024-04-12T08:27:11.104180Z"
    }
   },
   "id": "e7227ffd7e1cac4b"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "n_train, n_test = train_test_split(nodes, test_size=0.2)\n",
    "\n",
    "# pd.DataFrame(n_test).to_csv('./data/output/single/nodes_test.txt', index=False, header=False, sep=' ')\n",
    "\n",
    "n_train, n_valid = train_test_split(n_train, test_size=0.05)\n",
    "#pd.DataFrame(n_train).to_csv('./data/output/single/nodes_train.txt', index=False, header=False, sep=' ')\n",
    "#pd.DataFrame(n_valid).to_csv('./data/output/single/nodes_valid.txt', index=False, header=False, sep=' ')\n",
    "\n",
    "assert len(n_train) + len(n_test) + len(n_valid) == len(nodes)\n",
    "\n",
    "write_file(output + '/nodes_train.txt', n_train)\n",
    "write_file(output + '/nodes_valid.txt', n_valid)\n",
    "write_file(output + '/nodes_test.txt', n_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:11.406166Z",
     "start_time": "2024-04-12T08:27:11.106324Z"
    }
   },
   "id": "42cba7dd0a1007c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "save the nodes to a file, this is somewhat tricky, since some of the node texts contain newline characters, and we need to preserve them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65138b47f06d9c1d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "write_file(output + '/nodes.txt', nodes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:11.412361Z",
     "start_time": "2024-04-12T08:27:11.406262Z"
    }
   },
   "id": "629835bdd91d2459"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we follow Kepler@s Readme.md and prepare the KE and MLM data from the above files.\n",
    "    We will use the nodes...txt as our MLM data.\n",
    "    We will use the triples...txt as our KE data.\n",
    "    \n",
    "\n",
    "We first install the local version of kepler, which is built by extending fairsec:\n",
    "We now start with KE data preprocessing:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9a7127ab0453243"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Usage:   \r\n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\r\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\r\n",
      "  pip install [options] [-e] <vcs project url> ...\r\n",
      "  pip install [options] [-e] <local project path> ...\r\n",
      "  pip install [options] <archive url/path> ...\r\n",
      "\r\n",
      "no such option: --editable../../\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --editable../../"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:12.848198Z",
     "start_time": "2024-04-12T08:27:11.413041Z"
    }
   },
   "id": "d09453c865812ce0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Encode the entity descriptions with the GPT-2 BPE:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9854b2bd8151297c"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: illegal option -- .\r\n",
      "usage: mkdir [-pv] [-m mode] directory_name ...\r\n",
      "--2024-04-12 10:27:12--  ftp://https/\r\n",
      "           => ‘.listing’\r\n",
      "Resolving https (https)... failed: nodename nor servname provided, or not known.\r\n",
      "wget: unable to resolve host address ‘https’\r\n",
      "//: Scheme missing.\r\n",
      "--2024-04-12 10:27:12--  http://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\r\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 2600:9000:234e:a00:13:6e38:acc0:93a1, 2600:9000:234e:e200:13:6e38:acc0:93a1, 2600:9000:234e:c200:13:6e38:acc0:93a1, ...\r\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|2600:9000:234e:a00:13:6e38:acc0:93a1|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1042301 (1018K) [text/plain]\r\n",
      "Saving to: ‘../data/gpt2_bpe/encoder.json’\r\n",
      "\r\n",
      "../data/gpt2_bpe/en 100%[===================>]   1018K  --.-KB/s    in 0.1s    \r\n",
      "\r\n",
      "2024-04-12 10:27:13 (8.26 MB/s) - ‘../data/gpt2_bpe/encoder.json’ saved [1042301/1042301]\r\n",
      "\r\n",
      "FINISHED --2024-04-12 10:27:13--\r\n",
      "Total wall clock time: 1.0s\r\n",
      "Downloaded: 1 files, 1018K in 0.1s (8.26 MB/s)\r\n",
      "--2024-04-12 10:27:14--  ftp://https/\r\n",
      "           => ‘.listing’\r\n",
      "Resolving https (https)... failed: nodename nor servname provided, or not known.\r\n",
      "wget: unable to resolve host address ‘https’\r\n",
      "//: Scheme missing.\r\n",
      "--2024-04-12 10:27:14--  http://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\r\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 2600:9000:234e:a00:13:6e38:acc0:93a1, 2600:9000:234e:e200:13:6e38:acc0:93a1, 2600:9000:234e:c200:13:6e38:acc0:93a1, ...\r\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|2600:9000:234e:a00:13:6e38:acc0:93a1|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 456318 (446K) [text/plain]\r\n",
      "Saving to: ‘../data/gpt2_bpe/vocab.bpe’\r\n",
      "\r\n",
      "../data/gpt2_bpe/vo 100%[===================>] 445.62K  --.-KB/s    in 0.07s   \r\n",
      "\r\n",
      "2024-04-12 10:27:14 (6.24 MB/s) - ‘../data/gpt2_bpe/vocab.bpe’ saved [456318/456318]\r\n",
      "\r\n",
      "FINISHED --2024-04-12 10:27:14--\r\n",
      "Total wall clock time: 0.8s\r\n",
      "Downloaded: 1 files, 446K in 0.07s (6.24 MB/s)\r\n",
      "usage: multiprocessing_bpe_encoder.py [-h] [--encoder-json ENCODER_JSON]\r\n",
      "                                      [--vocab-bpe VOCAB_BPE]\r\n",
      "                                      [--inputs INPUTS [INPUTS ...]]\r\n",
      "                                      [--outputs OUTPUTS [OUTPUTS ...]]\r\n",
      "                                      [--keep-empty] [--workers WORKERS]\r\n",
      "multiprocessing_bpe_encoder.py: error: unrecognized arguments: --encoder-json../data/gpt2_bpe/encoder.json --vocab-bpe../data/gpt2_bpe/vocab.bpe --inputs../data/output/single/nodes.txt --outputs../data/output/single/nodes.bpe\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p../data/gpt2_bpe\n",
    "!wget -O../data/gpt2_bpe/encoder.json https: // dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n",
    "!wget -O../data/gpt2_bpe/vocab.bpe https: // dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\n",
    "\n",
    "!python -m examples.roberta.multiprocessing_bpe_encoder \\\n",
    "    --encoder-json../data/gpt2_bpe/encoder.json \\\n",
    "    --vocab-bpe../data/gpt2_bpe/vocab.bpe \\\n",
    "    --inputs../data/output/single/nodes.txt \\\n",
    "    --outputs../data/output/single/nodes.bpe \\\n",
    "    --keep-empty \\\n",
    "    --workers 60"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:20.531587Z",
     "start_time": "2024-04-12T08:27:12.850378Z"
    }
   },
   "id": "b43f735dfb9b6f4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Do negative sampling and dump the whole training and validation data:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d999e452c05d080b"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no such file or directory: python../../examples/KEPLER/Pretrain/KGpreprocess.py\r\n"
     ]
    }
   ],
   "source": [
    "!python../../examples/KEPLER/Pretrain/KGpreprocess.py --dumpPath../data/output/single/KE1 \\\n",
    "    -ns 1 \\\n",
    "    --ent_desc../data/output/single/nodes.bpe \\\n",
    "    --train../data/output/single/train.txt \\\n",
    "    --valid../data/output/single/valid.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:20.651536Z",
     "start_time": "2024-04-12T08:27:20.532783Z"
    }
   },
   "id": "299ef6c3b0bc945f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. then randomly split the KE training data into smaller parts and the number of training instances in each part aligns with the MLM training data\n",
    "For our case it will be just one split, since our data is small."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19491d497766b21e"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no such file or directory: python../../examples/KEPLER/Pretrain/splitDump.py\r\n"
     ]
    }
   ],
   "source": [
    "!python../../examples/KEPLER/Pretrain/splitDump.py --Path ../data/output/single/KE1 \\\n",
    "    --split_size 6834352 \\\n",
    "    --negative_sampling_size 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:27:20.768441Z",
     "start_time": "2024-04-12T08:27:20.652707Z"
    }
   },
   "id": "5ccac80a7fe44706"
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. We then binarize them for training:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b27bce6070479558"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-04-12 10:27:20--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 2600:9000:234e:a00:13:6e38:acc0:93a1, 2600:9000:234e:e200:13:6e38:acc0:93a1, 2600:9000:234e:c200:13:6e38:acc0:93a1, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|2600:9000:234e:a00:13:6e38:acc0:93a1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 603290 (589K) [text/plain]\n",
      "Saving to: ‘../data/gpt2_bpe/dict.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  8%  354K 2s\n",
      "    50K .......... .......... .......... .......... .......... 16%  340K 1s\n",
      "   100K .......... .......... .......... .......... .......... 25%  383K 1s\n",
      "   150K .......... .......... .......... .......... .......... 33% 7.93M 1s\n",
      "   200K .......... .......... .......... .......... .......... 42% 12.6M 1s\n",
      "   250K .......... .......... .......... .......... .......... 50% 18.7M 0s\n",
      "   300K .......... .......... .......... .......... .......... 59%  387K 0s\n",
      "   350K .......... .......... .......... .......... .......... 67% 10.3M 0s\n",
      "   400K .......... .......... .......... .......... .......... 76% 7.55M 0s\n",
      "   450K .......... .......... .......... .......... .......... 84% 50.0M 0s\n",
      "   500K .......... .......... .......... .......... .......... 93% 8.93M 0s\n",
      "   550K .......... .......... .......... .........            100% 8.75M=0.6s\n",
      "\n",
      "2024-04-12 10:27:22 (1011 KB/s) - ‘../data/gpt2_bpe/dict.txt’ saved [603290/603290]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(no_progress_bar=False, log_interval=1000, log_format=None, tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=False, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='nag', lr_scheduler='fixed', task='translation', source_lang=None, target_lang=None, trainpref='../data/output/single/KE1_0/head/train.bpe', validpref='../data/output/single/KE1_0/head/valid.bpe', testpref=None, destdir='../data/output/single/KE1_0/head', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='../data/gpt2_bpe//dict.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=True, padding_factor=8, workers=60, bert=False)\n",
      "| [None] Dictionary: 50263 types\n",
      "| [None] ../data/output/single/KE1_0/head/train.bpe: 11274 sents, 136102 tokens, 0.0% replaced by <unk>\n",
      "| [None] Dictionary: 50263 types\n",
      "| [None] ../data/output/single/KE1_0/head/valid.bpe: 594 sents, 7231 tokens, 0.0% replaced by <unk>\n",
      "| Wrote preprocessed data to ../data/output/single/KE1_0/head\n",
      "Namespace(no_progress_bar=False, log_interval=1000, log_format=None, tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=False, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='nag', lr_scheduler='fixed', task='translation', source_lang=None, target_lang=None, trainpref='../data/output/single/KE1_0/tail/train.bpe', validpref='../data/output/single/KE1_0/tail/valid.bpe', testpref=None, destdir='../data/output/single/KE1_0/tail', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='../data/gpt2_bpe//dict.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=True, padding_factor=8, workers=60, bert=False)\n",
      "| [None] Dictionary: 50263 types\n",
      "| [None] ../data/output/single/KE1_0/tail/train.bpe: 11274 sents, 113338 tokens, 0.0% replaced by <unk>\n",
      "| [None] Dictionary: 50263 types\n",
      "| [None] ../data/output/single/KE1_0/tail/valid.bpe: 594 sents, 5869 tokens, 0.0% replaced by <unk>\n",
      "| Wrote preprocessed data to ../data/output/single/KE1_0/tail\n",
      "Namespace(no_progress_bar=False, log_interval=1000, log_format=None, tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=False, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='nag', lr_scheduler='fixed', task='translation', source_lang=None, target_lang=None, trainpref='../data/output/single/KE1_0/negHead/train.bpe', validpref='../data/output/single/KE1_0/negHead/valid.bpe', testpref=None, destdir='../data/output/single/KE1_0/negHead', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='../data/gpt2_bpe//dict.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=True, padding_factor=8, workers=60, bert=False)\n",
      "| [None] Dictionary: 50263 types\n",
      "| [None] ../data/output/single/KE1_0/negHead/train.bpe: 11274 sents, 149652 tokens, 0.0% replaced by <unk>\n",
      "| [None] Dictionary: 50263 types\n",
      "| [None] ../data/output/single/KE1_0/negHead/valid.bpe: 594 sents, 7747 tokens, 0.0% replaced by <unk>\n",
      "| Wrote preprocessed data to ../data/output/single/KE1_0/negHead\n",
      "Namespace(no_progress_bar=False, log_interval=1000, log_format=None, tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=False, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='nag', lr_scheduler='fixed', task='translation', source_lang=None, target_lang=None, trainpref='../data/output/single/KE1_0/negTail/train.bpe', validpref='../data/output/single/KE1_0/negTail/valid.bpe', testpref=None, destdir='../data/output/single/KE1_0/negTail', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='../data/gpt2_bpe//dict.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=True, padding_factor=8, workers=60, bert=False)\n",
      "| [None] Dictionary: 50263 types\n",
      "| [None] ../data/output/single/KE1_0/negTail/train.bpe: 11274 sents, 150068 tokens, 0.0% replaced by <unk>\n",
      "| [None] Dictionary: 50263 types\n",
      "| [None] ../data/output/single/KE1_0/negTail/valid.bpe: 594 sents, 7588 tokens, 0.0% replaced by <unk>\n",
      "| Wrote preprocessed data to ../data/output/single/KE1_0/negTail\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wget -O ../data/gpt2_bpe/dict.txt https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt\n",
    "\n",
    "KE_Data=../data/output/single/KE1_0/\n",
    "for SPLIT in head tail negHead negTail;\n",
    "  do\n",
    "    python -m fairseq_cli.preprocess \\\n",
    "      --only-source \\\n",
    "      --srcdict ../data/gpt2_bpe//dict.txt \\\n",
    "      --trainpref ${KE_Data}${SPLIT}/train.bpe \\\n",
    "      --validpref ${KE_Data}${SPLIT}/valid.bpe \\\n",
    "      --destdir ${KE_Data}${SPLIT} \\\n",
    "      --workers 60; \\\n",
    "  done"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:29:14.596837Z",
     "start_time": "2024-04-12T08:27:20.769217Z"
    }
   },
   "id": "48e1031600c7930"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now start with MLM data preprocessing:\n",
    "\n",
    "\n",
    "1. Now we encode the nodes_train, nodes_train and nodes_valid with the GPT-2 BPE:\n",
    "   (gpt2_bpe is already downloaded during the KE data preparation, we reuse that.)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8025db8c495182b"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sougata/anaconda3/envs/kepler/lib/python3.12/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 53 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n",
      "/Users/sougata/anaconda3/envs/kepler/lib/python3.12/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 15 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ../data/output/single/MLM\n",
    "\n",
    "for SPLIT in train valid test; do \\\n",
    "    python -m examples.roberta.multiprocessing_bpe_encoder \\\n",
    "        --encoder-json ../data/gpt2_bpe/encoder.json \\\n",
    "        --vocab-bpe ../data/gpt2_bpe/vocab.bpe \\\n",
    "        --inputs ../data/output/single/nodes_${SPLIT}.txt \\\n",
    "        --outputs ../data/output/single/MLM/nodes_${SPLIT}.bpe \\\n",
    "        --keep-empty \\\n",
    "        --workers 60; \\\n",
    "done"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:29:54.212483Z",
     "start_time": "2024-04-12T08:29:14.598443Z"
    }
   },
   "id": "d0cd6deae6cbd2df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. We then preprocess/binarize the data using the GPT-2 fairseq dictionary:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29f69010e6eb7ac5"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(no_progress_bar=False, log_interval=1000, log_format=None, tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=False, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='nag', lr_scheduler='fixed', task='translation', source_lang=None, target_lang=None, trainpref='../data/output/single/MLM/nodes_train.bpe', validpref='../data/output/single/MLM/nodes_valid.bpe', testpref='../data/output/single/MLM/nodes_test.bpe', destdir='../data/output/single/MLM-bin', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='../data/gpt2_bpe/dict.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=True, padding_factor=8, workers=60, bert=False)\n",
      "| [None] Dictionary: 50263 types\n",
      "| [None] ../data/output/single/MLM/nodes_train.bpe: 4019 sents, 53508 tokens, 0.0% replaced by <unk>\n",
      "| [None] Dictionary: 50263 types\n",
      "| [None] ../data/output/single/MLM/nodes_valid.bpe: 212 sents, 2853 tokens, 0.0% replaced by <unk>\n",
      "| [None] Dictionary: 50263 types\n",
      "| [None] ../data/output/single/MLM/nodes_test.bpe: 1058 sents, 13799 tokens, 0.0% replaced by <unk>\n",
      "| Wrote preprocessed data to ../data/output/single/MLM-bin\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ../data/output/single/MLM-bin\n",
    "\n",
    "fairseq-preprocess \\\n",
    "    --only-source \\\n",
    "    --srcdict ../data/gpt2_bpe/dict.txt \\\n",
    "    --trainpref ../data/output/single/MLM/nodes_train.bpe \\\n",
    "    --validpref ../data/output/single/MLM/nodes_valid.bpe \\\n",
    "    --testpref ../data/output/single/MLM/nodes_test.bpe \\\n",
    "    --destdir ../data/output/single/MLM-bin \\\n",
    "    --workers 60"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:30:35.808008Z",
     "start_time": "2024-04-12T08:29:54.209071Z"
    }
   },
   "id": "5b00815d3e4ec9b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "All preprocessing is done, now we try out training the model with our data.\n",
    "\n",
    "We first download the pretrained models:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acb2ce7d3fd5a9f4"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: ../data/keplerModels: File exists\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\nmkdir ../data/keplerModels\\n\\nif ! [ -f ../data/keplerModels/KEPLERforNLP.pt ]; then\\n    wget -o ../data/keplerModels/KEPLERforNLP.pt https://cloud.tsinghua.edu.cn/seafhttp/files/a21e5254-ceac-4b88-88e9-8ec58cbe8a1a/KEPLERforNLP.pt\\nfi\\nif ! [ -f ../data/keplerModels/KEPLERforKE.p ]; then\\n    wget -o ../data/keplerModels/KEPLERforKE.pt https://cloud.tsinghua.edu.cn/seafhttp/files/a684dc30-6a1a-4613-97ad-0144ae84e1ca/KEPLERforKE.pt\\nfi\\n'' returned non-zero exit status 8.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_cell_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbash\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mmkdir ../data/keplerModels\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mif ! [ -f ../data/keplerModels/KEPLERforNLP.pt ]; then\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m    wget -o ../data/keplerModels/KEPLERforNLP.pt https://cloud.tsinghua.edu.cn/seafhttp/files/a21e5254-ceac-4b88-88e9-8ec58cbe8a1a/KEPLERforNLP.pt\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mfi\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mif ! [ -f ../data/keplerModels/KEPLERforKE.p ]; then\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m    wget -o ../data/keplerModels/KEPLERforKE.pt https://cloud.tsinghua.edu.cn/seafhttp/files/a684dc30-6a1a-4613-97ad-0144ae84e1ca/KEPLERforKE.pt\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mfi\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/kepler/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2517\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2515\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m   2516\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n\u001B[0;32m-> 2517\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   2519\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2520\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2521\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2522\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m~/anaconda3/envs/kepler/lib/python3.12/site-packages/IPython/core/magics/script.py:154\u001B[0m, in \u001B[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001B[0;34m(line, cell)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    153\u001B[0m     line \u001B[38;5;241m=\u001B[39m script\n\u001B[0;32m--> 154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshebang(line, cell)\n",
      "File \u001B[0;32m~/anaconda3/envs/kepler/lib/python3.12/site-packages/IPython/core/magics/script.py:314\u001B[0m, in \u001B[0;36mScriptMagics.shebang\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mraise_error \u001B[38;5;129;01mand\u001B[39;00m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001B[39;00m\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001B[39;00m\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     rc \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m9\u001B[39m\n\u001B[0;32m--> 314\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CalledProcessError(rc, cell)\n",
      "\u001B[0;31mCalledProcessError\u001B[0m: Command 'b'\\nmkdir ../data/keplerModels\\n\\nif ! [ -f ../data/keplerModels/KEPLERforNLP.pt ]; then\\n    wget -o ../data/keplerModels/KEPLERforNLP.pt https://cloud.tsinghua.edu.cn/seafhttp/files/a21e5254-ceac-4b88-88e9-8ec58cbe8a1a/KEPLERforNLP.pt\\nfi\\nif ! [ -f ../data/keplerModels/KEPLERforKE.p ]; then\\n    wget -o ../data/keplerModels/KEPLERforKE.pt https://cloud.tsinghua.edu.cn/seafhttp/files/a684dc30-6a1a-4613-97ad-0144ae84e1ca/KEPLERforKE.pt\\nfi\\n'' returned non-zero exit status 8."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir ../data/keplerModels\n",
    "\n",
    "if ! [ -f ../data/keplerModels/KEPLERforNLP.pt ]; then\n",
    "    wget -o ../data/keplerModels/KEPLERforNLP.pt https://cloud.tsinghua.edu.cn/seafhttp/files/a21e5254-ceac-4b88-88e9-8ec58cbe8a1a/KEPLERforNLP.pt\n",
    "fi\n",
    "if ! [ -f ../data/keplerModels/KEPLERforKE.p ]; then\n",
    "    wget -o ../data/keplerModels/KEPLERforKE.pt https://cloud.tsinghua.edu.cn/seafhttp/files/a684dc30-6a1a-4613-97ad-0144ae84e1ca/KEPLERforKE.pt\n",
    "fi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:30:37.600369Z",
     "start_time": "2024-04-12T08:30:35.811855Z"
    }
   },
   "id": "6aafe0205a95e34c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we first train on the NLP model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ffc15c847d3385d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "TOTAL_UPDATES=125000                                    # Total number of training steps\n",
    "WARMUP_UPDATES=10000                                    # Warmup the learning rate over this many updates\n",
    "LR=6e-04                                                # Peak LR for polynomial LR scheduler.\n",
    "NUM_CLASSES=2                           \n",
    "MAX_SENTENCES=3                                         # Batch size.\n",
    "NUM_NODES=1\t\t\t                                    # Number of machines\n",
    "ROBERTA_PATH=\"../data/keplerModels/KEPLERforNLP.pt\"     # Path to the original roberta model\n",
    "CHECKPOINT_PATH=\"../data/checkpoints\"                   # Directory to store the checkpoints\n",
    "UPDATE_FREQ=`expr 784 / $NUM_NODES`                     # Increase the batch size\n",
    "\n",
    "DATA_DIR=../data/output/single\n",
    "\n",
    "#Path to the preprocessed KE dataset, each item corresponds to a data directory for one epoch\n",
    "KE_DATA=$DATA_DIR/KE1_0:\n",
    "\n",
    "DIST_SIZE=`expr $NUM_NODES \\* 4`\n",
    "\n",
    "fairseq-train $DATA_DIR/MLM-bin --KEdata $KE_DATA --restore-file $ROBERTA_PATH \\\n",
    "        --save-dir $CHECKPOINT_PATH \\\n",
    "        --max-sentences $MAX_SENTENCES \\\n",
    "        --tokens-per-sample 512 \\\n",
    "        --task MLMetKE \\\n",
    "        --sample-break-mode complete \\\n",
    "        --required-batch-size-multiple 1 \\\n",
    "        --arch roberta_base \\\n",
    "        --criterion MLMetKE \\\n",
    "        --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \\\n",
    "        --optimizer adam --adam-betas \"(0.9, 0.98)\" --adam-eps 1e-06 \\\n",
    "        --clip-norm 0.0 \\\n",
    "        --lr-scheduler polynomial_decay --lr $LR --total-num-update $TOTAL_UPDATES --warmup-updates $WARMUP_UPDATES \\\n",
    "        --update-freq \"$UPDATE_FREQ\" \\\n",
    "        --negative-sample-size 1 --ke-model TransE \\\n",
    "        --init-token 0 \\\n",
    "        --separator-token 2 \\\n",
    "        --gamma 4 --nrelation 822 \\\n",
    "        --skip-invalid-size-inputs-valid-test \\\n",
    "        --fp16 --fp16-init-scale 2 --threshold-loss-scale 1 --fp16-scale-window 128 \\\n",
    "        --reset-optimizer --distributed-world-size \"${DIST_SIZE}\" --ddp-backend no_c10d --distributed-port 23456 \\\n",
    "        --log-format simple --log-interval 1 \\\n",
    "        #--relation-desc  #Add this option to encode the relation descriptions as relation embeddings (KEPLER-Rel in the paper)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:30:37.601218Z",
     "start_time": "2024-04-12T08:30:37.600940Z"
    }
   },
   "id": "db7756b7fda225dd"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "acd586a30a900481"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
